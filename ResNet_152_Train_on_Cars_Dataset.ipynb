{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet-152 Train on Cars Dataset.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yeqinghuang516/transfer-learning-and-inference-acceleration/blob/master/ResNet_152_Train_on_Cars_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10nWpps8aDz7",
        "colab_type": "text"
      },
      "source": [
        "## This notebook is RECOMMENDED to run on Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEZwP55iQyPJ",
        "colab_type": "text"
      },
      "source": [
        "## Copy our Project Repository from Github"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "epBtrAolPD59",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! git clone https://github.com/yeqinghuang516/transfer-learning-and-inference-acceleration.git\n",
        "% cd transfer-learning-and-inference-acceleration"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UssB0sFoQ3X7",
        "colab_type": "text"
      },
      "source": [
        "## Download the Training Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0H--W-QYIfh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget http://imagenet.stanford.edu/internal/car196/cars_train.tgz\n",
        "!wget https://ai.stanford.edu/~jkrause/cars/car_devkit.tgz\n",
        "!tar -xvf cars_train.tgz\n",
        "!tar -xvf car_devkit.tgz"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQJPZba0YF87",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib notebook\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "import torch.utils.data as td\n",
        "import torchvision as tv\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt\n",
        "import scipy.io\n",
        "import nntools as nt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyjK9HSZYF9C",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c099aeb0-577f-440d-8b81-04f54db8b6e2"
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KRjs_crfRVOZ",
        "colab_type": "text"
      },
      "source": [
        "## Define Dataset Class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TYE79GqRYF9N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class CarDataset(td.Dataset):\n",
        "    def __init__(self, root_dir, mode = 'train', image_size = (224,224), train = False):\n",
        "        super(CarDataset, self).__init__()\n",
        "        self.image_size = image_size\n",
        "        self.mode = mode\n",
        "        self.cars_annos = scipy.io.loadmat(root_dir + 'devkit/cars_' + mode + '_annos')\n",
        "        self.annos = self.cars_annos['annotations']\n",
        "        self.annos = np.transpose(self.annos)\n",
        "        self.images_dir = root_dir + 'cars_' + mode + '/'\n",
        "        self.train = train\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.annos.shape[0]\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.images_dir + \"%05d.jpg\" % (idx + 1)\n",
        "        bbox_x1 = self.annos[idx][0][0][0][0]\n",
        "        bbox_y1 = self.annos[idx][0][1][0][0]\n",
        "        bbox_x2 = self.annos[idx][0][2][0][0]\n",
        "        bbox_y2 = self.annos[idx][0][3][0][0]\n",
        "        d = self.annos[idx][0][4][0][0]\n",
        "        d = int(d)\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        img = img.crop([max(0 , bbox_x1 - 16), max(0, bbox_y1 - 16), min(img.size[0], bbox_x2 + 16), min(img.size[1], bbox_y2 + 16)])\n",
        "        h, w = img.size\n",
        "        dim_diff = np.abs(h - w)\n",
        "        pad1, pad2 = dim_diff // 2, dim_diff - dim_diff // 2\n",
        "        pad = (0, pad1, 0, pad2) if h >= w else (pad1, 0, pad2, 0)\n",
        "        data_aug = [\n",
        "            tv.transforms.RandomHorizontalFlip(),\n",
        "            tv.transforms.RandomAffine(10),\n",
        "            tv.transforms.RandomRotation(10),\n",
        "                   ]\n",
        "        \n",
        "        transform_list = [\n",
        "            tv.transforms.Pad(pad, fill = 0, padding_mode = 'constant'), \n",
        "            tv.transforms.Resize(self.image_size),\n",
        "            tv.transforms.ToTensor(),\n",
        "            tv.transforms.Normalize(mean = [0.5, 0.5 ,0.5], std = [0.5, 0.5 ,0.5]),\n",
        "        ]\n",
        "        \n",
        "        if self.train:\n",
        "          transform_list.insert(2, tv.transforms.ColorJitter(brightness= 0.5, contrast= 0.5, saturation= 0.5, hue=0.5))\n",
        "        \n",
        "        if self.train and np.random.random() < 0.5:\n",
        "          transform_list.insert(2, tv.transforms.RandomApply(data_aug))        \n",
        "        \n",
        "        transform = tv.transforms.Compose(transform_list)\n",
        "        \n",
        "        x = transform(img)\n",
        "        return x, (d - 1)\n",
        "    \n",
        "    def number_of_classes(self):\n",
        "        classes = []\n",
        "        for annotations in self.annos:\n",
        "            classes.append(annotations[0][4][0][0])\n",
        "        classes = np.array(classes)\n",
        "        return classes.max()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw8OFi5ERYLU",
        "colab_type": "text"
      },
      "source": [
        "## Initiate Training and Validation Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WB98Bc01YF9Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_root_dir = '/content/transfer-learning-and-inference-acceleration/'\n",
        "dataset = CarDataset(dataset_root_dir, train = True)\n",
        "\n",
        "full_length = len(dataset)\n",
        "train_size = int(0.7 * full_length)\n",
        "test_size = full_length - train_size\n",
        "idx = np.random.permutation(range(full_length))\n",
        "train_idx = idx[:train_size]\n",
        "test_idx = idx[train_size: ]\n",
        "\n",
        "trainset = td.Subset(dataset, train_idx)\n",
        "dataset = CarDataset(dataset_root_dir)\n",
        "testset = td.Subset(dataset, test_idx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mw4pfxwTSRHI",
        "colab_type": "text"
      },
      "source": [
        "## Define the Transferred Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPwxQtSgYF9i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NNClassifier(nt.NeuralNetwork):\n",
        "    def __init__(self):\n",
        "        super(NNClassifier, self).__init__()\n",
        "        self.cross_entropy = nn.CrossEntropyLoss()\n",
        "        \n",
        "    def criterion(self, y, d):\n",
        "        return self.cross_entropy(y, d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_PsjZ4RYF9u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResNet152Transfer(NNClassifier):\n",
        "    \n",
        "    def __init__(self, num_classes, fine_tuning=True):\n",
        "        super(ResNet152Transfer, self).__init__()\n",
        "        resnet152 = tv.models.resnet152(pretrained= True)\n",
        "        for param in resnet152.parameters():\n",
        "            param.requires_grad = fine_tuning\n",
        "                \n",
        "        self.model = resnet152\n",
        "        self.model.fc = nn.Linear(2048, num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "      y = self.model(x)\n",
        "      return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fv-SVxNPSVQ6",
        "colab_type": "text"
      },
      "source": [
        "## Define StatsManager for Recording Loss and Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bilecNv7YF92",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ClassificationStatsManager(nt.StatsManager):\n",
        "    def __init__(self):\n",
        "        super(ClassificationStatsManager, self).__init__()\n",
        "        \n",
        "    def init(self):\n",
        "        super(ClassificationStatsManager, self).init()\n",
        "        self.running_accuracy = 0\n",
        "        \n",
        "    def accumulate(self, loss, x, y, d):\n",
        "        super(ClassificationStatsManager, self).accumulate(loss, x, y, d)\n",
        "        _, l = torch.max(y, 1)\n",
        "        _, l_top5 = torch.topk(y, 5)\n",
        "\n",
        "        self.running_accuracy_top1 += torch.mean((l == d).float())\n",
        "        self.running_accuracy_top5 += torch.mean((l_top5 == d.view(-1,1).repeat(1,5)).float()) * 5\n",
        "        \n",
        "    def summarize(self):\n",
        "        loss = super(ClassificationStatsManager, self).summarize()\n",
        "        accuracy_top1 = 100 * self.running_accuracy_top1 / self.number_update\n",
        "        accuracy_top5 = 100 * self.running_accuracy_top5 / self.number_update\n",
        "        return {'loss': loss, 'top 1 accuracy': accuracy_top1, 'top 5 accuracy': accuracy_top5}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5CIHGS1SoHF",
        "colab_type": "text"
      },
      "source": [
        "## Initiate Experiment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R5sf1lBbYF95",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 1e-3\n",
        "net = ResNet152Transfer(dataset.number_of_classes())\n",
        "net = net.to(device)\n",
        "adam = torch.optim.Adam(net.parameters(), lr=lr)\n",
        "stats_manager = ClassificationStatsManager()\n",
        "exp1 = nt.Experiment(net, trainset, testset, adam, stats_manager,\n",
        "output_dir=\"ResNet152\", batch_size = 64, perform_validation_during_training=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZRaUoiVbxdl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot(exp):\n",
        "  if len(exp.history) is not 0:\n",
        "    print('training loss: ', exp.history[exp.epoch - 1][0]['loss'])\n",
        "    print('validation loss: ', exp.history[exp.epoch - 1][1]['loss'])\n",
        "    print('training accuracy: ', exp.history[exp.epoch - 1][0]['accuracy'])\n",
        "    print('validation accuracy: ', exp.history[exp.epoch - 1][1]['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mgK0VRx-Szst",
        "colab_type": "text"
      },
      "source": [
        "## Start Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vho5oLJ5YF99",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "exp1.run(num_epochs= 100, plot=lambda exp1: plot(exp1))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}