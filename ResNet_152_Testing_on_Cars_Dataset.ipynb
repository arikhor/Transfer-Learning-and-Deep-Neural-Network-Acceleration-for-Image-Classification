{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResNet-152 Testing on Cars Dataset.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yeqinghuang516/transfer-learning-and-inference-acceleration/blob/master/ResNet_152_Testing_on_Cars_Dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cm9VmwGnZ75F",
        "colab_type": "text"
      },
      "source": [
        "## This notebook is RECOMMENDED to run on Google Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BL4TXMGCZq5A",
        "colab_type": "text"
      },
      "source": [
        "## Clone our Project Repo from Github"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIEaxIiOZzF1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! git clone https://github.com/yeqinghuang516/transfer-learning-and-inference-acceleration.git\n",
        "% cd transfer-learning-and-inference-acceleration"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TPdkVSMrZ5PO",
        "colab_type": "text"
      },
      "source": [
        "## Download Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywEyB_nPrv-n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! wget http://imagenet.stanford.edu/internal/car196/car_ims.tgz\n",
        "! wget http://imagenet.stanford.edu/internal/car196/cars_annos.mat\n",
        "! tar -xvf car_ims.tgz\n",
        "! tar -xvf cars_annos.mat"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lls5XkxXq3nS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%matplotlib notebook\n",
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "import torch.utils.data as td\n",
        "import torchvision as tv\n",
        "import pandas as pd\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt\n",
        "import scipy.io\n",
        "import nntools as nt\n",
        "import time\n",
        "from download_weights import download_file_from_google_drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "asoWopeoro9n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FullCarDataset(td.Dataset):\n",
        "    def __init__(self, root_dir, image_size = (224, 224)):\n",
        "        super(FullCarDataset, self).__init__()\n",
        "        self.root_dir = root_dir\n",
        "        self.image_size = image_size\n",
        "        self.cars_annos = scipy.io.loadmat(root_dir + 'cars_annos.mat')\n",
        "        self.annos = self.cars_annos['annotations']\n",
        "        self.annos = np.transpose(self.annos)\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.annos.shape[0]\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.root_dir + self.annos[idx][0][0][0]\n",
        "        bbox_x1 = self.annos[idx][0][1][0][0]\n",
        "        bbox_y1 = self.annos[idx][0][2][0][0]\n",
        "        bbox_x2 = self.annos[idx][0][3][0][0]\n",
        "        bbox_y2 = self.annos[idx][0][4][0][0]\n",
        "        d = self.annos[idx][0][5][0][0]\n",
        "        d = int(d)\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        img = img.crop([max(0 , bbox_x1 - 16), max(0, bbox_y1 - 16), min(img.size[0], bbox_x2 + 16), min(img.size[1], bbox_y2 + 16)])\n",
        "        h, w = img.size\n",
        "        dim_diff = np.abs(h - w)\n",
        "        # (upper / left) padding and (lower / right) padding\n",
        "        pad1, pad2 = dim_diff // 2, dim_diff - dim_diff // 2\n",
        "        # Determine padding\n",
        "        pad = (0, pad1, 0, pad2) if h >= w else (pad1, 0, pad2, 0)   # left, top, right and bottom\n",
        "        # Add padding\n",
        "        img = tv.transforms.functional.pad(img, pad,fill = 0, padding_mode = 'constant' )\n",
        "        transform = tv.transforms.Compose([\n",
        "            tv.transforms.Resize(self.image_size),\n",
        "            tv.transforms.ToTensor(),\n",
        "            tv.transforms.Normalize(mean = [0.5, 0.5 ,0.5], std = [0.5, 0.5 ,0.5]),\n",
        "            ])\n",
        "        \n",
        "        x = transform(img)\n",
        "        return x, (d - 1)\n",
        "    \n",
        "    def number_of_classes(self):\n",
        "        classes = []\n",
        "        for annotations in self.annos:\n",
        "            classes.append(annotations[0][5][0][0])\n",
        "        classes = np.array(classes)\n",
        "        return classes.max()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "45AX78TDtYqS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1PWurMTYeQqH",
        "colab_type": "text"
      },
      "source": [
        "## Download the Weight Stored in Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yP8Zlp5EtYsP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_id = '1-0FLcfLlxW5AJMXFv_HmqLsKVyCzGxsU'\n",
        "destination = '/content/transfer-learning-and-inference-acceleration/checkpoint.pth.tar'\n",
        "download_file_from_google_drive(file_id, destination)\n",
        "pretrained_weights = '/content/transfer-learning-and-inference-acceleration/checkpoint.pth.tar'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uzOQXtTbMBe",
        "colab_type": "text"
      },
      "source": [
        "## Initiate Testing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZgTRzfO7tYuZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_root_dir = '/content/transfer-learning-and-inference-acceleration/'\n",
        "fullDataset = FullCarDataset(dataset_root_dir)\n",
        "testset = td.Subset(fullDataset, range(8143, len(fullDataset)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lf8ZAH2dc_mf",
        "colab_type": "text"
      },
      "source": [
        "## Define the Transferred Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bMRxyMx5tYwm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NNClassifier(nt.NeuralNetwork):\n",
        "    def __init__(self):\n",
        "        super(NNClassifier, self).__init__()\n",
        "        self.cross_entropy = nn.CrossEntropyLoss()\n",
        "        \n",
        "    def criterion(self, y, d):\n",
        "        return self.cross_entropy(y, d)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ed2NVaMgtY1O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ResNet152Transfer(NNClassifier):\n",
        "    \n",
        "    def __init__(self, num_classes, fine_tuning=True):\n",
        "        super(ResNet152Transfer, self).__init__()\n",
        "        resnet152 = tv.models.resnet152(pretrained=False)\n",
        "        for param in resnet152.parameters():\n",
        "            param.requires_grad = fine_tuning\n",
        "                \n",
        "        self.model = resnet152\n",
        "        self.model.fc = nn.Linear(2048, num_classes)\n",
        "        \n",
        "        \n",
        "        \n",
        "    def forward(self, x):\n",
        "      y = self.model(x)\n",
        "      return y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZ0fuDcQdGJo",
        "colab_type": "text"
      },
      "source": [
        "## Define the StatsManager for Recording the Loss and Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vgqFT4CCtY5J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class ClassificationStatsManager(nt.StatsManager):\n",
        "    def __init__(self):\n",
        "        super(ClassificationStatsManager, self).__init__()\n",
        "        \n",
        "    def init(self):\n",
        "        super(ClassificationStatsManager, self).init()\n",
        "        self.running_accuracy_top1 = 0\n",
        "        self.running_accuracy_top5 = 0\n",
        "        \n",
        "    def accumulate(self, loss, x, y, d):\n",
        "        super(ClassificationStatsManager, self).accumulate(loss, x, y, d)\n",
        "        _, l = torch.max(y, 1)\n",
        "        _, l_top5 = torch.topk(y, 5)\n",
        "        self.running_accuracy_top1 += torch.mean((l == d).float())\n",
        "        self.running_accuracy_top5 += torch.mean((l_top5 == d.view(-1,1).repeat(1,5)).float()) * 5\n",
        "        \n",
        "        \n",
        "    def summarize(self):\n",
        "        loss = super(ClassificationStatsManager, self).summarize()\n",
        "        accuracy_top1 = 100 * self.running_accuracy_top1 / self.number_update\n",
        "        accuracy_top5 = 100 * self.running_accuracy_top5 / self.number_update\n",
        "        return {'loss': loss, 'top 1 accuracy': accuracy_top1, 'top 5 accuracy': accuracy_top5}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_lTVYE7-tYoK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(net, val_set):\n",
        "    \"\"\"Evaluates the experiment, i.e., forward propagates the validation set\n",
        "    through the network and returns the statistics computed by the stats\n",
        "    manager.\n",
        "    \"\"\"\n",
        "    stats_manager = ClassificationStatsManager()\n",
        "    net.eval()\n",
        "    val_loader = td.DataLoader(val_set, batch_size= 256, shuffle=False, drop_last=False, pin_memory=True)\n",
        "    with torch.no_grad():\n",
        "        for x, d in val_loader:\n",
        "            x, d = x.to(net.device), d.to(net.device)\n",
        "            y = net.forward(x)\n",
        "            loss = net.criterion(y, d)\n",
        "            stats_manager.accumulate(loss.item(), x, y, d)\n",
        "            \n",
        "    net.train()\n",
        "    return stats_manager.summarize()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tJ6hhPPdycX",
        "colab_type": "text"
      },
      "source": [
        "## Initiate the Network and Load Weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkCQsdmC02k3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "net = ResNet152Transfer(196)\n",
        "net = net.to(device)\n",
        "checkpoint_path = '/content/transfer-learning-and-inference-acceleration/checkpoint.pth.tar'\n",
        "checkpoint = torch.load(checkpoint_path,map_location= net.device)\n",
        "net.load_state_dict(checkpoint['Net']);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zVcNythKd1ge",
        "colab_type": "text"
      },
      "source": [
        "## Conduct Evaluation on Testing Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mR9Pkujd8pIZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "evaluate(net, testset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QE0SRt1xd5Pp",
        "colab_type": "text"
      },
      "source": [
        "## Plot a sample graph for a single prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eNa0DNLNJly",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "% matplotlib inline\n",
        "img_idx = np.random.randint(len(fullDataset))\n",
        "\n",
        "x, d = fullDataset[img_idx]\n",
        "x = x[None,:,:,:]\n",
        "d = torch.tensor(d)\n",
        "\n",
        "net.eval();\n",
        "\n",
        "with torch.no_grad():\n",
        "  x, d = x.to(net.device), d.to(net.device)\n",
        "  y = net.forward(x)\n",
        "  y = torch.exp(y) / torch.exp(y).sum()\n",
        "  conf1 , label1 = torch.max(y, 1)\n",
        "  conf5, label5 = torch.topk(y, 5)\n",
        "\n",
        "  \n",
        "  \n",
        "x = torch.flatten(x, start_dim = 0, end_dim = 1)\n",
        "x = x.to('cpu').numpy()\n",
        "x = np.moveaxis(x, [0, 1, 2], [2, 0 ,1])\n",
        "x = (x + 1) / 2\n",
        "x[x > 1] = 1\n",
        "x[x < 0] = 0\n",
        "conf5, label5 = conf5.to('cpu').numpy(), label5.to('cpu').numpy()\n",
        "conf5 = np.concatenate(conf5)\n",
        "label5 = list(np.concatenate(label5))\n",
        "\n",
        "\n",
        "\n",
        "fig = plt.figure(figsize = (18, 10) )\n",
        "ax1 = fig.add_subplot(121)\n",
        "ax1.imshow(x)\n",
        "ax1.set_title('Predicted: %d, Actual: %d' %(label5[0], d), fontsize = 18)\n",
        "ax2 = fig.add_subplot(122)\n",
        "ax2.barh(range(5), conf5)\n",
        "ax2.invert_yaxis()\n",
        "ax2.set_yticklabels([0] + label5, fontsize = 18);\n",
        "ax2.set_title('Top 5 Predictions', fontsize = 18)\n",
        "ax2.set_ylabel('Predicted Class', fontsize = 18)\n",
        "ax2.set_xlabel('Confidence', fontsize = 18)\n",
        "\n",
        "for i, v in enumerate(conf5):\n",
        "  ax2.text(v + 0.01, i, str(np.round(v, decimals = 4)), fontweight='bold', fontsize = 14)\n",
        "\n",
        "\n",
        "net.train();"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}